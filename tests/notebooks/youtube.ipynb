{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from treeck import SplitTree\n",
    "from treeck.xgb import addtree_from_xgb_model\n",
    "from treeck.verifier import Verifier\n",
    "from treeck.distributed import DistributedVerifier\n",
    "from treeck.z3backend import Z3Backend as Backend\n",
    "import z3\n",
    "\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"~/kuleuven/phd/data\"\n",
    "data = pd.read_hdf(os.path.join(DATA_PATH, \"youtube\", \"youtube.h5\"))\n",
    "\n",
    "num_examples = data.shape[0]\n",
    "num_features = data.shape[1]\n",
    "\n",
    "np.random.seed(222)\n",
    "indices = np.random.permutation(num_examples)\n",
    "\n",
    "m = int(num_examples*0.9)\n",
    "Itrain = indices[0:m]\n",
    "Itest = indices[m:]\n",
    "\n",
    "wordsonly_data = data.iloc[:, 0:373]\n",
    "\n",
    "Xtrain = wordsonly_data.iloc[Itrain, :].to_numpy()\n",
    "Xtest = wordsonly_data.iloc[Itest, :].to_numpy()\n",
    "ytrain = data.iloc[Itrain, -1].to_numpy()\n",
    "ytest = data.iloc[Itest, -1].to_numpy()\n",
    "\n",
    "dtrain = xgb.DMatrix(Xtrain, label=ytrain, missing=None)\n",
    "dtest = xgb.DMatrix(Xtest, label=ytest, missing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"max_depth\": 10,\n",
    "    \"learning_rate\": 0.5,\n",
    "    \"eval_metric\": \"mae\",\n",
    "    \"seed\": 0,\n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round=50,\n",
    "                  early_stopping_rounds=5,\n",
    "                  evals=[(dtrain, \"train\"), (dtest, \"test\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "at = addtree_from_xgb_model(num_features, model)\n",
    "pred_m = model.predict(xgb.DMatrix(Xtest[:1000, :]))\n",
    "pred_a = at.predict(Xtest[:1000, :])\n",
    "mae_m = mean_absolute_error(ytest[:1000], pred_m)\n",
    "mae_a = mean_absolute_error(ytest[:1000], pred_a)\n",
    "\n",
    "print(f\"xgb: {mae_m}, at: {mae_a} diff: {mean_absolute_error(pred_m, pred_a)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (41, 'txt_black_panther')\n",
    "# (204, 'txt_marvel'),\n",
    "# (215, 'txt_movie'),\n",
    "# (216, 'txt_movies'),\n",
    "\n",
    "words2id = dict([(w[4:], i) for i, w in enumerate(wordsonly_data.columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vfactory(at, leaf):\n",
    "    offset = 10\n",
    "    max_sum_offset = 50\n",
    "    v = Verifier(at, leaf, Backend(), num_instances=2)\n",
    "    \n",
    "    pbeq = []\n",
    "    for w, i in words2id.items():\n",
    "        xvar0, xvar1 = v.xvar(i, instance=0), v.xvar(i, instance=1)\n",
    "        if w in [\"marvel\", \"black_panther\", \"movie\", \"movies\"]:\n",
    "            v.add_constraint((xvar0 == 1.0) & (xvar1 == 1.0))\n",
    "        else:\n",
    "            bvar_name = f\"flag{i}\"\n",
    "            v.add_bvar(bvar_name)\n",
    "            bvar = v.bvar(bvar_name)\n",
    "            v.add_constraint(z3.If(bvar.get(), xvar0.get() != xvar1.get(),\n",
    "                                               xvar0.get() == xvar1.get()))\n",
    "            pbeq.append((bvar.get(), 1))\n",
    "\n",
    "    v.add_constraint(z3.PbEq(pbeq, 1)) # at most N variables differ\n",
    "    v.add_constraint(v.fvar(instance=0) > v.fvar(instance=1))\n",
    "\n",
    "    return v\n",
    "\n",
    "with Client(\"tcp://localhost:30333\") as client:\n",
    "    client.restart()\n",
    "    st = SplitTree(at, {})\n",
    "    dv = DistributedVerifier(client, st, vfactory,\n",
    "            check_paths = True,\n",
    "            saturate_workers_factor=1,\n",
    "            stop_when_sat = False)\n",
    "    dv.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from treeck.plot import TreePlot\n",
    "\n",
    "g = TreePlot()\n",
    "g.add_tree(dv._st.domtree())\n",
    "g.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "edf94335a57343e48734aacebd5abf4a",
   "lastKernelId": "2654a1d1-277e-4241-aedf-36ca51d0abbc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
